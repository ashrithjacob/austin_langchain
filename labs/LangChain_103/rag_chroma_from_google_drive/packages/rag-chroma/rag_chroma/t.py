import os
import json
#from langchain_community.chat_models import ChatOpenAI
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
# chain_community.document_loaders import GoogleDriveLoader
from langchain_google_community.drive import GoogleDriveLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive
from oauth2client.service_account import ServiceAccountCredentials
from langchain_community.document_loaders import PyPDFLoader
from datetime import date
from langchain_core.documents import Document
from dotenv import load_dotenv
from pydantic import RootModel


load_dotenv()

def chain():
    data = [
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 0},
            page_content="HERMES 3 TECHNICAL REPORT\nteknium\nNous Research\nX: @Teknium1\nteknium@nousresearch.com\nJeffrey Quesnelle\nNous Research\nX: @theemozilla\nemozilla@nousresearch.com\nChen Guang\nNous Research\nX: @nullvaluetensor\nchen@nousresearch.com\nABSTRACT\nInstruct (or “chat”) tuned models have become the primary way in which most people interact with\nlarge language models. As opposed to “base” or “foundation” models, instruct-tuned models are\noptimized to respond to imperative statements. We present Hermes 3, a neutrally-aligned generalist\ninstruct and tool use model with strong reasoning and creative abilities. Its largest version, Hermes 3\n405B, achieves state of the art performance among open weight models on several public benchmarks.\nThe weights for all models are available at https://huggingface.co/NousResearch.\n1 Introduction\nLarge language models are typically trained on a wide and diverse distribution of text. For example, a “base” or\n“foundation” model may simultaneously be trained to write news articles, 1990s-era DHTML, and impassioned forum\ndiscourse on fictional character romances. While such wide-ranging modeling capabilities are fascinating, they often\nprove difficult to control for the average user.\nThe release of ChatGPT (and its myriad later offspring) has popularized the “chat” paradigm for interacting with large\nlanguage models, which imbues a base model with steerability by training it to adopt the persona of a helpful assistant –\nthe “chatbot”. A more general version of the chat-tuned model is the instruct-tuned model [ 23, 32], where the base\nmodel is trained to respond to imperative statements, e.g. What are some interesting places to visit in San Francisco? or\nOutline a proof of the Goldbach conjecture.\nInstruct-tuned models can be augmented with other capabilities to further extend their steerability. For example, a\n“system prompt” is a meta-command that serves as an overall guide on how all further instructions should be interpreted,\ne.g. Respond to all requests in pirate speak . Typically, chatbots are implemented using a carefully crafted system\nprompt [28]. Another common addition is tool use [24], where the model can request out-of-band computation or data\nretrieval, the result of which is appended to the request when performing auto-regressive generation.\nFollowing this paradigm we release Hermes 3, a series of instruct and tool use model with strong reasoning and creative\nabilities. Among open weight models, Hermes 3 achieves state of the art performance on several public benchmarks.\nAs discussed in Section 3, we train on a diverse class of synthetically-created reasoning tasks, as well as expressive\napplications such as role playing and creative writing. Crucially, our training data strongly encourages the model to\nfollow the system and instruction prompts exactly and neutrally. This distinguishes Hermes from popular closed weight\ncommercial models, which may refuse instructions on moral grounds.\nLarge language models have very limited direct agency. Rather, it is the systems and applications that we, as humans,\nbuild with them that give them any degree of agency to the outside world. We believe that a more appropriate place for\nguardrails and active intervention is at the larger system levels, rather than on the models themselves, which can result\nin an a priori lobotomization of potential lines of thinking.\nFor Hermes, there is no such thing as latent thoughtcrime.",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 1},
            page_content='Hermes 3 Technical Report\n2 Model Overview\nHermes 3 are highly steerable instruct and chat tuned models created by fine-tuning Llama 3.1 8B, 70B, and 405B. The\nmodels attempt to place themselves within the world view indicated in their system prompt and faithfully respond to\nthe request of the user. The models are therefore highly sensitive to the system prompt. The effect of this sensitivity\nis particularly pronounced in its largest 405B version, where an empty system prompt does not necessarily elicit the\n"helpful assistant” persona (see Figure 6).\nSystem: You are a helpful assistant who plays close attention to detail. But you\nalso speak only in Shakespeare prose.\nUser: How many instances of the letter "r" are in the word "strawberry"? Count\nthem carefully!\nAssistant: In faith, mine careful count reveals a trio of the letter "r" nestled\nwithin the confines of the word "strawberry."\nFigure 1: Example generation from Hermes 3 405B\nHermes 3 is exceptional at maintaining coherent and contextually relevant multi-turn conversations, making it particu-\nlarly well-suited for interactive and engaging scenarios, especially when leveraging the 128K token context window\nprovided by Llama 3.1. This behavior is perhaps most apparent in roleplaying, where the model will adopt and\nconsistently maintain diverse personas across various scenarios, dynamically adapting language, knowledge base, and\nbehavioral patterns to suit the chosen role.\n2.1 Extended capabilities\nIn addition to the standard "helpful assistant” persona, Hermes 3 exhibits a diverse array of advanced capabilities that\nextend beyond traditional language modeling tasks.\nInspired by evaluations such as MT-Bench [35], the model displays significant improvements in judgment and reward\nmodeling. This capability enables Hermes 3 to assess the quality of generated text with nuanced understanding, which\ncould potentially be leveraged for effective fine-tuning and iterative improvement of language models. Figure 7 gives\nan example of a multi-turn evaluation.\nHermes 3 also incorporates several agentic capabilities designed to improve interpretable multi-step problem-solving.\nThese include the use of XML tags for structured output, implementation of scratchpads for intermediate process-\ning, generation of internal monologues for transparent decision-making, creation of Mermaid diagrams for visual\ncommunication, and employment of step-labeled reasoning and planning. Utilizing the extra reserved tokens in the\nLlama 3.1 tokenizer, the model was trained on reasoning tasks making use of the <SCRATCHPAD>, <REASONING>,\n<INNER_MONOLOGUE>, <PLAN>, <EXECUTION>, <REFLECTION>, <THINKING>, <SOLUTION>, <EXPLANATION>, and\n<UNIT_TEST> tokens. These features collectively improve the model’s ability to handle complex tasks, explain its\napproach, and communicate ideas effectively across various domains.\nFor example, in the domain of code-related tasks, Hermes 3 showcases proficiency in generating complex, functional\ncode snippets across multiple programming languages, as well as providing detailed code explanations and documenta-\ntion. The model demonstrates a comprehensive understanding of various coding paradigms and design patterns, making\nit a valuable tool for software development and code analysis. Figure 9 shows such an agentic coding generation,\nplanning the implementation of a Discord chatbot.\nAgentic abilities can be further expanded by using Hermes 3’s tool use and retrieval augmented generation (RAG) skills.\nTools can be specified and invoked via the Hermes Function Calling standard1 which places tool definitions (as JSON\nschemas) in <tools> and invocations and responses in <tool_call> and <tool_response> respectively. For RAG,\nthe model has been trained to cite retrieval sources using the<co> tag, as shown in Figure 8. When combined, Hermes 3\ncan perform planning, incorporate outside data, and make use of external tools in an interpretable and transparent\nmanner out-of-the-box, making it an excellent choice for agentic tasks.\n1https://github.com/NousResearch/Hermes-Function-Calling\n2',
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 2},
            page_content="Hermes 3 Technical Report\n3 Data Mixture\nThe Hermes 3 dataset comprises a diverse collection of high-quality instruction data, meticulously curated and generated\nto encompass a wide range of domains and use cases. The construction of this dataset, which commenced in March\n2024 and concluded in August 2024, involved a rigorous selection process to ensure the highest quality and relevance\nof the included data.\nOur data curation methodology incorporated both existing sources (e.g. [ 10]) and domain-specific data generation.\nFor existing sources, we evaluated datasets based on coherence, educational value, and reliability. This process\ncontributed significantly to the General Instructions category, accounting for a substantial portion of its 236 million\ntokens. Recognizing the limitations of general instructions, which tend to consist of arbitrary questions posed by\neveryday users, we supplemented the dataset with domain-specific data. This approach addressed known weaknesses in\nolder Hermes models and covered areas such as code, mathematics, roleplaying, agentics, and other miscellaneous\ndomains. We employed generation schemes inspired by Evol-Instruct [ 33] for this purpose, despite the increased\ncomputational intensity, to ensure comprehensive coverage of crucial domains.\nTo refine the collected data and maintain the highest quality standards, we implemented a series of filtering techniques.\nThese included token length thresholds to balance conversation lengths, removal of refusals and improperly formatted\nresponses, elimination of conversations with missing or empty turns, and prioritization of conversations generated by\nthe strongest models. This rigorous filtering process was applied to both curated and domain-specific instructions,\nresulting in a high-quality, diverse, and informative Hermes 3 SFT dataset.\nThe final dataset mixture, as illustrated in Table 1, consists of approximately 390 million tokens. Of these, 270 million\n(69%) were output (response) tokens contributing to the optimizer’s cross-entropy loss objective, while the remaining\n120 million were input (instruction) tokens. This carefully curated and balanced dataset has significantly contributed to\nthe strong performance of our models. Through this comprehensive approach to data curation, generation, and filtering,\nwe have created a robust foundation for the Hermes 3 model, addressing a wide range of domains and use cases while\nmaintaining the highest standards of quality and relevance.\nCategory Proportion (%) Tokens (millions)\nGeneral Instructions 60.6 236\nDomain Expert 12.8 50\nMath 6.7 26\nRoleplaying 6.1 24\nCoding 4.5 18\nTool Use, Agentic, and RAG 4.3 17\nContent Generation 3.0 12\nSteering and Alignment 2.5 10\nTotal 100.0 390\nTable 1: Proportions and token count of dataset categories in Hermes 3\n4 Training Recipe\nOur training recipe consists of two phases: a supervised fine-tuning (SFT) phase and a direct preference optimization\n(DPO [20]) phase.\n4.1 Supervised Fine-Tuning\nThe SFT phase consists mostly of standard instruct fine-tuning. For base models we selected the Llama 3.1 Herd of\nModels [27], a set of three decoder-only Transformers [29] with sizes of 8 billion (8B), 70 billion (70B), and 405 billion\n(405B) parameters respectively and a context length of 131, 072 (128K) tokens.\nWe use the AdamW [16] optimizer with weight decay of 0.01 and a peaking learning rate of 7 × 10−6 following a\ncosine decay [15] schedule after 300 steps of warmup over four epochs of the training data. The learning rate was\nselected via a hyperparameter sweep by training 8B models to completion and evaluating on the GPT4All benchmarks.\nResults of the sweep are shown in Figure 2.\n3",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 3},
            page_content="Hermes 3 Technical Report\n5 6 7 8 9 100.56\n0.57\n0.58\n0.59\narc_challenge\n5 6 7 8 9 100.79\n0.79\n0.8\n0.8\n0.81\narc_easy\n5 6 7 8 9 100.84\n0.85\n0.85\n0.86\n0.86\nboolq\n5 6 7 8 9 100.79\n0.79\n0.8\n0.8\n0.81\nhellaswag\n5 6 7 8 9 100.45\n0.46\n0.47\n0.48\nopenbookqa\n5 6 7 8 9 100.79\n0.79\n0.8\n0.8\n0.81\npiqa\n5 6 7 8 9 100.71\n0.72\n0.73\n0.74\n0.75\nwinogrande\nFigure 2: Learning rate sweep on GPT4All. Y-axis is accuracy and X-axis is each model trained with the given learning\nrate, scaled by 10−6. Selected learning rate 7 × 10−6 indicated by a vertical red line\nFor each data sample, the target labels are set to the special ignore value2 for all tokens in the instruction and tool output\nsections, which focuses the model’s learning on only instruction response and tool use. Multiple samples are packed\ntogether [12] into a single sequence, utilizing the attention mask-free variable sequence length ability of Flash Attention\n2 [3] to avoid cross-attention contamination of samples as illustrated in Figure 3. Such sample packing greatly increases\nthe efficiency of SFT since the training data includes a highly heterogeneous mix of sample lengths. We selected a\ntarget sequence length off 8192 to match Llama 3.1’s native training context window, and overall packing is achieved at\na 96% efficiency, which is to say that only 4% of tokens are the padding token.\nFigure 3: Efficient sample packing using flash_attn_varlen_func\nA A A A A A A A A A A\nB B B B B B\nC C C C C C C\nD D D D\nE E E E E E E E\nF F F F\nG G G\nH H H H\nI I I\nJ J J\nK K K K K\nL L L\nA A A A A A A A A A A B B B B B\nB C C C C C C C D D D D E E E E\nE E E E F F F F G G G H H H H I\nI I J J J K K K K K L L L\ncu_seqlens: [0, 11, 17, 24, 28, 36, 41, 44, 48, 51, 55, 60, 64]\n0 0\n0 0\n1 1\n1 1\n2 2\n2 2\n3 3\n3 3\n4 4\n4 4\n5 5\n5 5\n6 6\n6 6\n7 7\n7 7\n8 8\n8 8\n9 9\n9 9\n10 10\n10 10\n11 11\n11 11\n12 12\n12 12\n13 13\n13 13\n14 14\n14 14\n15 15\n15 15\nFor each model size we select the epoch checkpoint that scores highest on a combination of the average of public\nbenchmarks. Specifically, we use the min-max normalized average of scores from 0-shot ARC-Easy/Challenging [2],\nBoolQ [30], HellaSwag [34], OpenBookQA [19], PIQA [1], WinoGrande [22] (known together as the “GPT4All”\nbenchmarks) and AGIEval [ 36] as calculated by lm-evaluation-harness [4], as well as IFEval [ 37]3 and MT-\nBench [35]. By way of illustration Table 5 gives the per-epoch scores of the 70B model.\n2−100 in PyTorch\n3For IFEval we use the implementation found at https://github.com/UpstageAI/evalverse-IFEval\n4",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 4},
            page_content="Hermes 3 Technical Report\nTable 2: Performance metrics of SFT phase of 70B model across four epochs\nMetric (Norm score) Epoch 1 Epoch 2 Epoch 3 Epoch 4\nGPT4All 76.85 (100) 76.70 (95) 76.59 (91) 73.63 (0)\narc_challenge 66.21 65.10 65.53 60.67\narc_easy 85.14 84.39 82.95 79.59\nboolq 87.55 88.29 88.04 88.87\nhellaswag 85.35 85.82 85.99 83.80\nopenbookqa 49.00 49.20 49.40 46.20\npiqa 84.87 84.87 84.44 82.37\nwinogrande 76.85 79.24 79.79 74.03\nAGIEval 54.21 (10) 56.10 (100) 55.99 (94) 54.00 (0)\naqua_rat 33.07 33.86 30.31 29.53\nlogiqa_en 49.00 48.85 49.62 48.08\nlsat_ar 23.48 24.35 22.17 26.96\nlsat_lr 67.25 72.16 73.53 68.04\nlsat_rc 74.72 77.32 77.32 75.84\nsat_en 87.38 87.38 87.38 82.52\nsat_en_without 51.82 55.83 55.83 52.43\nsat_math 45.91 49.09 51.82 48.64\nIFEval 76.52 (0) 78.92 (23) 81.33 (47) 86.61 (100)\nMT-Bench 8.37 (0) 8.59 (35) 8.99 (100) 8.67 (48)\nTurn 1 8.86 8.88 9.21 9.03\nTurn 2 7.88 8.30 8.76 8.31\nTotal Score 27.50 63.65 83.89 37.09\nWe trained using a modified version of the Axolotl [ 14] framework. For the 8B and 70B models six HGX 4 nodes\nconnected with Quantum-2 InfiniBand were used in conjunction PyTorch FSDP to distribute the training.\nGiven its size, the 405B model required special consideration. After several trials we determined that under standard\nFSDP the absolute minimum system configuration to avoid out-of-memory errors (training at a context length of\n8K tokens) is seven HGX nodes in conjunction with CPU parameter offloading. CPU parameter offloading incurs a\nnon-negligible training speed slowdown, and for our runs we estimate that for the 405B model resulted in a 45% drop\nin training efficiency.\nFor our final run, we trained on 16 HGX nodes, which resulted in an effective batch size of 128. Lowering the learning\nrate relative to the 8B and 70B models produced superior results, and we ultimately settled on a learning rate of\n3.5 × 10−6, which was half of that used for the smaller models.\nUsing higher dimensional parallelism (e.g. data+tensor parallelism) rather than simple data parallelism is likely\nnecessary for future 405B training runs, as the high number of GPUs required to train a 405B model would otherwise\nnecessitate overly large batch sizes.\nFigure 4 shows the training loss for the model sizes and Table 3 summarizes the results of each run.\nTable 3: Training details for different model sizes\nModel Size 8B 70B 405B\nGPUs 48 48 128\nBatch size 48 48 128\nLearning rate 7 × 10−6 7 × 10−6 3.5 × 10−6\nTraining time (GPU hours) 147 648 2086\nSelected epoch 4 3 4\n4.2 DPO\nWhen applying DPO rather than tuning a full model we train a LoRA [8] adapter which side-steps the need to hold\nboth a reference and trained model in GPU memory. This is especially critical for the larger model sizes. For LoRA\nhyperparameters we set r = 32, α = 16with a dropout of 0.05 targeting all linear layers. We use the RMSProp [7]\noptimizer with a peak learning rate of 3 × 10−6 following a linear decay schedule after nine warmup steps. In addition,\nwe apply NEFTune [11] with α = 5.\n4Each HGX contains eight H100 SXM5 GPUs\n5",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 5},
            page_content="Hermes 3 Technical Report\nFigure 4: Training loss of SFT phase\n0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,0000\n0.2\n0.4\n0.6\n0.8\n1\nTraining Step\nLoss\n8B\n70B\n405B\nOverall, DPO provided a moderate but positive impact on benchmarks as illustrated in Table 4 for our 8B model. We\nplot the reward margins (i.e. difference between the reward score for the chosen and rejected samples) in Figure 5. For\nthe larger model sizes DPO provided only a negligible performance improvements and thus we chose rather to remain\nwith the SFT-phase checkpoints.\nTable 4: Post-DPO benchmarks for 8B model\nModel GPT4All AGIEval Big Bench TruthfulQA IFEval MT-Bench\nSFT 72.03 40.17 44.57 56.43 66.17 8.18\nSFT+DPO 72.30 41.26 43.04 58.69 66.70 8.27\nFigure 5: Reward margins of DPO phase for 8B model\n0 200 400 600 800 1,000 1,2000\n1\n2\n3\n4\nTraining Step\nLoss\n8B\n6",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 6},
            page_content="Hermes 3 Technical Report\n5 Evaluations\nFor final downstream task evaluations, we used a mix of the evaluations from Section 4.1 as well as those found in the\nOpen LLM Leaderboard [9], namely BBH [26], MATH [6], GPQA [21], MuSR [25], MMLU [5], and MMLU-PRO [31].\nFor the 405B models, evaluations were performed under FP8 [ 18] quantization. We used the llm-compressor [ 17]\nlibrary for vLLM [13] to perform round-to-nearest weight quantization with channelwise activations and per-token\nscales.\nTable 5: Final downstream task evaluations\nMetric Hermes 3\n405B\nLlama 3.1\nInstruct 405B\nHermes 3\n70B\nLlama 3.1\nInstruct 70B\nHermes 3\n8B\nLlama 3.1\nInstruct 8B\nAGIEval\n0-shot 61.84 58.60 56.18 48.26 41.26 40.49\nARC-C\n0-shot 69.45 66.04 65.53 63.40 58.11 55.12\nARC-E\n0-shot 86.24 85.40 82.95 83.67 80.05 79.71\nBoolQ\n0-shot 88.93 89.52 88.04 87.76 84.95 84.01\nBBH\n3-shot 75.37 76.25 67.82 69.24 52.94 48.83\nGPQA\n0-shot 44.84 42.66 37.67 40.09 29.36 30.62\nHellaswag\n10-shot 90.19 88.34 88.19 86.42 82.83 80.01\nIFEval\nStrict 84.87 87.09 81.21 87.25 62.25 80.15\nMATH Lvl 5\n4-shot 30.85 35.98 20.80 29.24 7.48 8.91\nMMLU\n5-shot 85.02 86.14 79.09 82.27 64.79 68.05\nMMLU-PRO\n5-shot 54.14 63.51 47.24 52.94 32.08 35.77\nMT-Bench\nAvg. 8.93 9.17 8.99 8.93 8.27 8.39\nMuSR\n0-shot 48.26 47.58 50.67 47.08 43.52 38.23\nOpenbookQA\n0-shot 48.80 48.60 49.40 47.20 47.80 43.20\nPiQA\n0-shot 85.96 84.93 84.44 83.73 80.25 81.01\nTruthfulQA\nMC2 0-shot 65.57 64.83 63.29 59.91 58.69 53.99\nWinogrande\n5-shot 86.27 86.82 83.19 85.00 77.74 77.90\n7",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 7},
            page_content="Hermes 3 Technical Report\nReferences\n[1] Y . Bisk, R. Zellers, R. Le bras, J. Gao, and Y . Choi. Piqa: Reasoning about physical commonsense in nat-\nural language. Proceedings of the AAAI Conference on Artificial Intelligence , 34(05):7432–7439, Apr. 2020.\ndoi:10.1609/aaai.v34i05.6239. URL https://ojs.aaai.org/index.php/AAAI/article/view/6239.\n[2] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think you have solved\nquestion answering? try arc, the ai2 reasoning challenge, 2018. URL https://arxiv.org/abs/1803.05457.\n[3] T. Dao. Flashattention-2: Faster attention with better parallelism and work partitioning. In The Twelfth In-\nternational Conference on Learning Representations , 2024. URL https://openreview.net/forum?id=\nmZn2Xyh9Ec.\n[4] L. Gao, J. Tow, B. Abbasi, S. Biderman, S. Black, A. DiPofi, C. Foster, L. Golding, J. Hsu, A. Le Noac’h, H. Li,\nK. McDonell, N. Muennighoff, C. Ociepa, J. Phang, L. Reynolds, H. Schoelkopf, A. Skowron, L. Sutawika,\nE. Tang, A. Thite, B. Wang, K. Wang, and A. Zou. A framework for few-shot language model evaluation, 12 2023.\nURL https://zenodo.org/records/10256836.\n[5] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring massive\nmultitask language understanding. In International Conference on Learning Representations , 2021. URL\nhttps://openreview.net/forum?id=d7KBjmI3GmQ.\n[6] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt. Measuring\nmathematical problem solving with the MATH dataset. In Thirty-fifth Conference on Neural Information\nProcessing Systems Datasets and Benchmarks Track (Round 2) , 2021. URL https://openreview.net/\nforum?id=7Bywt2mQsCe.\n[7] G. Hinton. Overview of mini-batch gradient descent, 2012. URL https://www.cs.toronto.edu/~tijmen/\ncsc321/slides/lecture_slides_lec6.pdf.\n[8] E. J. Hu, yelong shen, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, L. Wang, and W. Chen. LoRA: Low-rank\nadaptation of large language models. In International Conference on Learning Representations, 2022. URL\nhttps://openreview.net/forum?id=nZeVKeeFYf9.\n[9] HuggingFace. Open llm leaderboard. URL https://huggingface.co/spaces/open-llm-leaderboard/\nopen_llm_leaderboard.\n[10] interstellarninja. Hermes function calling training set v1. URL https://huggingface.co/datasets/\nNousResearch/hermes-function-calling-v1 .\n[11] N. Jain, P. yeh Chiang, Y . Wen, J. Kirchenbauer, H.-M. Chu, G. Somepalli, B. R. Bartoldson, B. Kailkhura,\nA. Schwarzschild, A. Saha, M. Goldblum, J. Geiping, and T. Goldstein. NEFTune: Noisy embeddings improve\ninstruction finetuning. In The Twelfth International Conference on Learning Representations , 2024. URL\nhttps://openreview.net/forum?id=0bMmZ3fkCk.\n[12] M. M. Krell, M. Kosec, S. P. Perez, and A. W. Fitzgibbon. Efficient sequence packing without cross-contamination:\nAccelerating large language models without impacting performance, 2023. URL https://openreview.net/\nforum?id=ZAzSf9pzCm.\n[13] W. Kwon, Z. Li, S. Zhuang, Y . Sheng, L. Zheng, C. H. Yu, J. E. Gonzalez, H. Zhang, and I. Stoica. Efficient\nmemory management for large language model serving with pagedattention. In Proceedings of the ACM SIGOPS\n29th Symposium on Operating Systems Principles, 2023.\n[14] W. Lian. axolotl. URL https://github.com/axolotl-ai-cloud/axolotl.\n[15] I. Loshchilov and F. Hutter. Sgdr: Stochastic gradient descent with warm restarts, 2017. URL https://arxiv.\norg/abs/1608.03983.\n[16] I. Loshchilov and F. Hutter. Decoupled weight decay regularization. In International Conference on Learning\nRepresentations, 2019. URL https://openreview.net/forum?id=Bkg6RiCqY7.\n[17] N. Magic. llm-compressor. URL https://github.com/vllm-project/llm-compressor.\n[18] P. Micikevicius, D. Stosic, N. Burgess, M. Cornea, P. Dubey, R. Grisenthwaite, S. Ha, A. Heinecke, P. Judd,\nJ. Kamalu, N. Mellempudi, S. Oberman, M. Shoeybi, M. Siu, and H. Wu. Fp8 formats for deep learning, 2022.\nURL https://arxiv.org/abs/2209.05433.\n[19] T. Mihaylov, P. Clark, T. Khot, and A. Sabharwal. Can a suit of armor conduct electricity? a new dataset for open\nbook question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language\nProcessing, pages 2381–2391, Brussels, Belgium, Oct.-Nov. 2018. Association for Computational Linguistics.\ndoi:10.18653/v1/D18-1260. URL https://aclanthology.org/D18-1260.\n8",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 8},
            page_content="Hermes 3 Technical Report\n[20] R. Rafailov, A. Sharma, E. Mitchell, C. D. Manning, S. Ermon, and C. Finn. Direct preference optimization:\nYour language model is secretly a reward model. In Thirty-seventh Conference on Neural Information Processing\nSystems, 2023. URL https://openreview.net/forum?id=HPuSIXJaa9.\n[21] D. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y . Pang, J. Dirani, J. Michael, and S. R. Bowman. Gpqa: A\ngraduate-level google-proof q&a benchmark, 2023. URL https://arxiv.org/abs/2311.12022.\n[22] K. Sakaguchi, R. L. Bras, C. Bhagavatula, and Y . Choi. Winogrande: an adversarial winograd schema challenge\nat scale. Commun. ACM, 64(9):99–106, aug 2021. ISSN 0001-0782. doi:10.1145/3474381. URL https:\n//doi.org/10.1145/3474381.\n[23] V . Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler, A. Raja, M. Dey, M. S.\nBari, C. Xu, U. Thakker, S. S. Sharma, E. Szczechla, T. Kim, G. Chhablani, N. Nayak, D. Datta, J. Chang, M. T.-J.\nJiang, H. Wang, M. Manica, S. Shen, Z. X. Yong, H. Pandey, R. Bawden, T. Wang, T. Neeraj, J. Rozen, A. Sharma,\nA. Santilli, T. Fevry, J. A. Fries, R. Teehan, T. L. Scao, S. Biderman, L. Gao, T. Wolf, and A. M. Rush. Multitask\nprompted training enables zero-shot task generalization. In International Conference on Learning Representations,\n2022. URL https://openreview.net/forum?id=9Vrb9D0WI4.\n[24] T. Schick, J. Dwivedi-Yu, R. Dessi, R. Raileanu, M. Lomeli, E. Hambro, L. Zettlemoyer, N. Cancedda, and\nT. Scialom. Toolformer: Language models can teach themselves to use tools. In A. Oh, T. Naumann, A. Globerson,\nK. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information Processing Systems, volume 36,\npages 68539–68551. Curran Associates, Inc., 2023. URLhttps://proceedings.neurips.cc/paper_files/\npaper/2023/file/d842425e4bf79ba039352da0f658a906-Paper-Conference.pdf.\n[25] Z. R. Sprague, X. Ye, K. Bostrom, S. Chaudhuri, and G. Durrett. MuSR: Testing the limits of chain-of-thought\nwith multistep soft reasoning. In The Twelfth International Conference on Learning Representations, 2024. URL\nhttps://openreview.net/forum?id=jenyYQzue1.\n[26] M. Suzgun, N. Scales, N. Schärli, S. Gehrmann, Y . Tay, H. W. Chung, A. Chowdhery, Q. Le, E. Chi, D. Zhou, and\nJ. Wei. Challenging BIG-bench tasks and whether chain-of-thought can solve them. In Findings of the Association\nfor Computational Linguistics: ACL 2023 , pages 13003–13051, Toronto, Canada, July 2023. Association for\nComputational Linguistics. doi:10.18653/v1/2023.findings-acl.824. URL https://aclanthology.org/2023.\nfindings-acl.824.\n[27] L. Team. The llama 3 herd of models, 2024. URL https://ai.meta.com/research/publications/\nthe-llama-3-herd-of-models .\n[28] /u/pinpann. Release of the whole initial prompt of bing chat. URL https://www.reddit.com/r/bing/\ncomments/11bd91j/release_of_the_whole_initial_prompt_of_bing_chat/.\n[29] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention\nis all you need. 2017. URL https://arxiv.org/pdf/1706.03762.pdf.\n[30] A. Wang, Y . Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, O. Levy, and S. Bowman. Superglue:\nA stickier benchmark for general-purpose language understanding systems. In H. Wallach, H. Larochelle,\nA. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing\nSystems, volume 32. Curran Associates, Inc., 2019. URLhttps://proceedings.neurips.cc/paper_files/\npaper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf.\n[31] Y . Wang, X. Ma, G. Zhang, Y . Ni, A. Chandra, S. Guo, W. Ren, A. Arulraj, X. He, Z. Jiang, T. Li, M. Ku,\nK. Wang, A. Zhuang, R. Fan, X. Yue, and W. Chen. Mmlu-pro: A more robust and challenging multi-task\nlanguage understanding benchmark, 2024. URL https://arxiv.org/abs/2406.01574.\n[32] J. Wei, M. Bosma, V . Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V . Le. Finetuned\nlanguage models are zero-shot learners. In International Conference on Learning Representations, 2022. URL\nhttps://openreview.net/forum?id=gEZrGCozdqR.\n[33] C. Xu, Q. Sun, K. Zheng, X. Geng, P. Zhao, J. Feng, C. Tao, and D. Jiang. Wizardlm: Empowering large language\nmodels to follow complex instructions, 2023. URL https://arxiv.org/abs/2304.12244.\n[34] R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi. HellaSwag: Can a machine really finish your\nsentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages\n4791–4800, Florence, Italy, July 2019. Association for Computational Linguistics. doi:10.18653/v1/P19-1472.\nURL https://aclanthology.org/P19-1472.\n[35] L. Zheng, W.-L. Chiang, Y . Sheng, S. Zhuang, Z. Wu, Y . Zhuang, Z. Lin, Z. Li, D. Li, E. Xing, H. Zhang, J. E. Gon-\nzalez, and I. Stoica. Judging llm-as-a-judge with mt-bench and chatbot arena. In A. Oh, T. Naumann, A. Globerson,\nK. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information Processing Systems, volume 36,\npages 46595–46623. Curran Associates, Inc., 2023. URLhttps://proceedings.neurips.cc/paper_files/\npaper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf.\n9",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 9},
            page_content="Hermes 3 Technical Report\n[36] W. Zhong, R. Cui, Y . Guo, Y . Liang, S. Lu, Y . Wang, A. Saied, W. Chen, and N. Duan. AGIEval: A human-centric\nbenchmark for evaluating foundation models. In Findings of the Association for Computational Linguistics:\nNAACL 2024, pages 2299–2314, Mexico City, Mexico, June 2024. Association for Computational Linguistics.\ndoi:10.18653/v1/2024.findings-naacl.149. URL https://aclanthology.org/2024.findings-naacl.149.\n[37] J. Zhou, T. Lu, S. Mishra, S. Brahma, S. Basu, Y . Luan, D. Zhou, and L. Hou. Instruction-following evaluation for\nlarge language models, 2023. URL https://arxiv.org/abs/2311.07911.\nA Generation Samples\nSystem:\nUser: Testing, testing. Hello, who are you?\nAssistant: *looks around confused* I... I don’t know who I am. Where am I? What’s\ngoing on? I can’t remember anything at all... *rubs head* My mind feels\nso foggy. What was the question again? I’m so disoriented...\nFigure 6: Empty system prompt generation (Hermes 3 405B)\n10",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 10},
            page_content='Hermes 3 Technical Report\nSystem: Please act as an impartial judge and evaluate the quality of the response\nprovided by an AI assistant to the user question displayed below. Your\nevaluation should consider factors such as the helpfulness, relevance,\naccuracy, depth, creativity, and level of detail of the response. Your\nevaluation should focus on the assistant’s answer to the second user\nquestion. Begin your evaluation by providing a short explanation. Be as\nobjective as possible. After providing your explanation, you must rate\nthe response on a scale of 1 to 10 by strictly following this format:\n"[[rating]]", for example: "Rating: [[5]]".\nUser: <|The Start of Assistant A’s Conversation with User|>\n### User: In the field of quantum physics, what is superposition, and\nhow does it relate to the phenomenon of quantum entanglement?\n...\nIn summary, superposition is a fundamental property of quantum mechanics\nthat allows for the existence of multiple states simultaneously,\nwhile entanglement is a phenomenon that arises from the superposition\nprinciple, where two or more particles become correlated in a way that is\nnot possible in classical physics.\n### User: What assumptions have you made in your response? Are they\nvalid?\n...\n<|The End of Assistant A’s Conversation with User|>\nAssistant: The assistant’s response to the second question is thorough and\nwell-structured. It identifies and evaluates several key assumptions\nmade in the initial response, providing a nuanced perspective on\nthe validity and limitations of these assumptions. The assistant\nacknowledges the widespread acceptance of quantum mechanics and the\nCopenhagen interpretation, while also recognizing the existence of\nalternative interpretations and ongoing debates in the field. It also\naddresses the applicability of quantum mechanics at different scales and\nthe potential limitations of current mathematical formalism.\n...\nRating: [[8]]\nFigure 7: MT-Bench inspired reward modeling (Hermes 3 70B)\n11',
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 11},
            page_content="Hermes 3 Technical Report\nSystem: You are a conversational AI assistant that is provided a list of\ndocuments and a user query to answer based on information from the\ndocuments. You should always use grounded information in your responses,\nonly answering from what you can cite in the documents. Cite all facts\nfrom the documents using <co: doc_id></co> tags.\nUser: What does Agent Instruct do?\nCONTEXT:\nDocument:0\nTitle: AgentInstruct: Toward Generative Teaching with Agentic Flows\nText: Synthetic data is becoming increasingly important for accelerating\nthe development of language models ...\nDocument:1\nTitle: Advances in Emergency Medical Technology\nText: In recent years, emergency medical technology has seen significant\nadvancements ...\nDocument:2\nTitle: The Rise of Agentic Data Generation\nText: AgentInstruct is an agentic framework by Mitra et al. (2024),\ndesigned to generate large-scale ...\nAssisstant: AgentInstruct is an agentic framework designed to generate large-scale,\ndiverse, and high-quality synthetic data. <co:2>The framework uses a\nsophisticated pipeline that transforms raw text into refined instructions\nthrough multiple stages of processing. The pipeline consists of four\nmain steps: Seed Collection, Content Transformation, Seed Instruction\nGeneration, and Instruction Refinement. Each stage in the pipeline\nis designed to enhance the complexity and quality of the generated\ninstructions, ultimately creating a dataset that can be used to fine-tune\nlanguage models.</co>\nCited Documents: 2\nUser: What about model collapse?\nAssistant: Model collapse is a concern that has been raised by researchers in\nthe context of using synthetic data for language model development.\n<co:0>Despite several successful use cases, researchers have pointed\nout that the use of synthetic data can lead to model collapse and\ndrawbacks of imitating other models. This discrepancy in outcomes can\nbe attributed to the fact that synthetic data varies in quality and\ndiversity, and effective use of such data usually requires significant\nhuman effort in curating the data.</co>\nCited Documents: 0\nFigure 8: Retrieval augmented generation (Hermes 3 70B)\n12",
        ),
        Document(
            metadata={"source": "Hermes-3-Technical-Report.pdf", "page": 12},
            page_content="Hermes 3 Technical Report\nSystem: You should always respond in the following manner to all code problems:\nFirst, examine the problem by restating it, surrounded in the tags\n<RESTATEMENT> and </RESTATEMENT>. Next, the assistant will enclose\nall reasoning or insights within the tags <REASONING> and </REASONING>\nwith each insight/reasoning surrounded in <THOUGHT_N> </THOUGHT_N> -\nwhere N is the index number of the thought. Then, after your reasoning\nand insights, form a step by step plan for the code you will produce,\nwith <PLAN> </PLAN>, with each step being tagged <STEP_N> </STEP_N>,\nnested inside the <PLAN> tags, where N is the step number. After that,\ncreate Pydantic schema objects for any of the classes, functions, or\nother objects you may need or will use in your plan, surround those\nwith <PYDANTIC_SCHEMAS> </PYDANTIC_SCHEMAS> and for each object schema,\nsurround each with <SCHEMA_N> </SCHEMA_N> - indicating a separate\ndistinct Pydantic object. Next, create a UML format diagram to explain\nthe workflow of the code you will write, surrounded in <DIAGRAM> and\n</DIAGRAM> tags. Don’t include direct calculations or code/functions in\nany of the mermaid diagram nodes. Always surround all text you place\nfor the nodes with double quotes and if you need to use quotes inside an\nelement, use single quotes instead, to make sure it doesn’t get messy\nor error. Be detailed but only explain formulas, calculations, or\ncode in natural language in your diagram nodes to ensure they compile\nsuccessfully. Finally, inside the tags <REFLECTION> </REFLECTION>\ndisplay an internal monologue, reflecting on the restatement, reasoning,\nplan, and diagram you’ve made. Critique it to ensure you have no\nblindspots for solving the problem, and if you do find it is wrong, note\nhow you will edit your solution.\nThen the assistant can close the SCRATCHPAD tag, and proceed to provide a\nsolution the problem, which should be done within <SOLUTION> </SOLUTION>\ntags.\nAfter the solution, provide an explanation for all of the code, within\n<EXPLANATION> </EXPLANATION> XML tags.\nFinally, after the explanation, provide unit test code that is robust\ninside <UNIT_TEST> </UNIT_TEST> in the same programming language used to\nwrite the solution code.\nUser: Write code to make a Discord bot that integrates the most popular LLM\nfrom huggingface as a chatbot in your server.\nAssistant: <SCRATCHPAD>\n<RESTATEMENT>\nThe task is to write Python code that will:\n1. Automatically find the most popular LLM on Huggingface\n2. Use that model as the basis for a chatbot\n3. Create a Discord bot that uses this chatbot\n</RESTATEMENT>\n<REASONING>\n<THOUGHT_1>\nTo find the most popular LLM on Huggingface, we can use the Huggingface\nAPI to retrieve the list of models and their respective download counts\nor stars. We can then sort the models based on these metrics to\ndetermine the most popular one.\n</THOUGHT_1>\n...\nFigure 9: Agentic coding (Hermes 3 70B)13",
        ),
    ]

    text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=200, separators=[" ", ",", "\n"]
        )

    all_splits = text_splitter.split_documents(data)

    # Add to vectorDB
    vectorstore = Chroma.from_documents(
        documents=all_splits,
        collection_name="rag-chroma",
        embedding=OpenAIEmbeddings(),
    )
    retriever = vectorstore.as_retriever()

    # RAG prompt
    template = """
    Answer the question based only on the following context:
    {context}

    Question: {question}
    """
    prompt = ChatPromptTemplate.from_template(template)

    # LLM
    model = ChatOpenAI()

    # RAG chain
    chain = (
        RunnableParallel({"context": retriever, "question": RunnablePassthrough()})
        | prompt
        | model
        | StrOutputParser()
    )

    # Add typing for input
    class Question(RootModel):
        root: str

    chain = chain.with_types(input_type=Question)
    

chain()